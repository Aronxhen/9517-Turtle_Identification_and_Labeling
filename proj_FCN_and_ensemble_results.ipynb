{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Fully Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.Create data dictionary by train, valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T18:48:54.267649Z",
     "start_time": "2024-11-02T18:48:53.816938Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-03T11:21:40.322833Z",
     "iopub.status.busy": "2024-11-03T11:21:40.322178Z",
     "iopub.status.idle": "2024-11-03T11:21:40.969751Z",
     "shell.execute_reply": "2024-11-03T11:21:40.968278Z",
     "shell.execute_reply.started": "2024-11-03T11:21:40.322805Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set number: 5303\n",
      "valid set number: 1118\n",
      "test set number: 2308\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>split_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>images/t001/CAluWEgwPX.JPG</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>images/t001/EKyrFKHQzh.JPG</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>images/t001/ELAvEqeXxT.JPG</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>images/t001/IxRLFwTGCv.JPG</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>images/t001/LKCJAhfLBJ.JPG</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8724</th>\n",
       "      <td>8725</td>\n",
       "      <td>images/t610/miUGGSioXO.jpeg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8725</th>\n",
       "      <td>8726</td>\n",
       "      <td>images/t610/aOzTdMCkzF.jpeg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8726</th>\n",
       "      <td>8727</td>\n",
       "      <td>images/t610/ZmTLXySHIZ.jpeg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>8728</td>\n",
       "      <td>images/t610/qVDYBLbzda.jpeg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>8729</td>\n",
       "      <td>images/t610/THVsdHexWD.jpeg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8729 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                    file_name split_open\n",
       "0        1   images/t001/CAluWEgwPX.JPG      train\n",
       "1        2   images/t001/EKyrFKHQzh.JPG      train\n",
       "2        3   images/t001/ELAvEqeXxT.JPG      train\n",
       "3        4   images/t001/IxRLFwTGCv.JPG      train\n",
       "4        5   images/t001/LKCJAhfLBJ.JPG      train\n",
       "...    ...                          ...        ...\n",
       "8724  8725  images/t610/miUGGSioXO.jpeg       test\n",
       "8725  8726  images/t610/aOzTdMCkzF.jpeg       test\n",
       "8726  8727  images/t610/ZmTLXySHIZ.jpeg       test\n",
       "8727  8728  images/t610/qVDYBLbzda.jpeg       test\n",
       "8728  8729  images/t610/THVsdHexWD.jpeg       test\n",
       "\n",
       "[8729 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata splits using your local route\n",
    "meta_split = pd.read_csv('data/metadata_splits.csv')  # Adjusted path for your project folder\n",
    "\n",
    "# Extract main data columns\n",
    "meta_data = meta_split[['id', 'file_name', 'split_open']]\n",
    "\n",
    "# Get unique data types (train, valid, test)\n",
    "data_type = set(meta_data['split_open'])\n",
    "\n",
    "# Create a dictionary to hold data for each type\n",
    "meta_data_dict = {}\n",
    "for type in data_type:\n",
    "    meta_data_dict[type] = []\n",
    "\n",
    "# Populate the dictionary with IDs and file names based on data type\n",
    "for index, row in meta_data.iterrows():\n",
    "    meta_data_dict[row['split_open']].append((row['id'], row['file_name']))\n",
    "\n",
    "# Print the number of images in each set\n",
    "print(f\"train set number: {len(meta_data_dict['train'])}\")\n",
    "print(f\"valid set number: {len(meta_data_dict['valid'])}\")\n",
    "print(f\"test set number: {len(meta_data_dict['test'])}\")\n",
    "\n",
    "# Display the main metadata dataframe\n",
    "meta_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Set class dataset by using coco\n",
    "\n",
    "for getting image and mask, then we can put into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:21:38.797792Z",
     "start_time": "2024-11-02T19:21:38.794131Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-03T11:21:41.384407Z",
     "iopub.status.busy": "2024-11-03T11:21:41.384176Z",
     "iopub.status.idle": "2024-11-03T11:21:46.532352Z",
     "shell.execute_reply": "2024-11-03T11:21:46.531464Z",
     "shell.execute_reply.started": "2024-11-03T11:21:41.384385Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.models.segmentation\n",
    "import torch.optim as optim \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:21:43.793679Z",
     "start_time": "2024-11-02T19:21:42.080450Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-03T11:21:46.533956Z",
     "iopub.status.busy": "2024-11-03T11:21:46.533435Z",
     "iopub.status.idle": "2024-11-03T11:21:51.147120Z",
     "shell.execute_reply": "2024-11-03T11:21:51.145924Z",
     "shell.execute_reply.started": "2024-11-03T11:21:46.533928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.70s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# set img dir\n",
    "image_dir = 'data/images'\n",
    "\n",
    "# json to coco\n",
    "coco = COCO('data/annotations.json')\n",
    "\n",
    "# image and mask transform method\n",
    "transform_method = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "target_transform_method = transforms.Compose([\n",
    "    transforms.Resize((512, 512), interpolation=Image.NEAREST), \n",
    "    transforms.Lambda(lambda mask: torch.from_numpy(np.array(mask)).long())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:22:52.853217Z",
     "start_time": "2024-11-02T19:22:52.847273Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-03T11:21:51.149082Z",
     "iopub.status.busy": "2024-11-03T11:21:51.148800Z",
     "iopub.status.idle": "2024-11-03T11:21:51.169600Z",
     "shell.execute_reply": "2024-11-03T11:21:51.168958Z",
     "shell.execute_reply.started": "2024-11-03T11:21:51.149056Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, coco, meta_data_dict, data_type, transform=None, target_transform=None):\n",
    "        self.image_dir = image_dir  # original image dir\n",
    "        self.coco = coco # coco\n",
    "        self.data_type = data_type # train valid test\n",
    "        self.transform = transform  # transform method\n",
    "        self.target_transform = target_transform  # transform method\n",
    "        self.images = [] # all original images path in train set\n",
    "\n",
    "        data_list = meta_data_dict[self.data_type]\n",
    "        img_Ids = self.coco.getImgIds()\n",
    "\n",
    "        for i in img_Ids:\n",
    "            # if img_id in data_type list is true\n",
    "            if any(t[0] == i for t in data_list):\n",
    "                self.images.append(self.coco.loadImgs(i)[0])\n",
    "\n",
    "    def process_mask(self, image_id, image):\n",
    "        category_map = {\n",
    "            1: 1,  # turtles\n",
    "            2: 2,  # flipper\n",
    "            3: 3   # head\n",
    "        }\n",
    "        \n",
    "        mask = np.zeros((image.size[1], image.size[0]), dtype=np.uint8)\n",
    "        for cat_id, target_value in category_map.items():\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_id, catIds=cat_id, iscrowd=None)\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "            for ann in anns:\n",
    "                ann_mask = self.coco.annToMask(ann)\n",
    "                mask[ann_mask > 0] = target_value  \n",
    "                \n",
    "        return mask\n",
    "\n",
    "    def __len__(self):  # set dataset size\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        # Get image ID\n",
    "        img_id = img['id']\n",
    "        # Get image file name\n",
    "        img_file_name = img['file_name']\n",
    "\n",
    "        # Construct the full image path\n",
    "        if img_file_name.startswith('images/'):  # Check if the path already includes 'images'\n",
    "            image_path = os.path.join(self.image_dir, img_file_name.split('images/', 1)[-1])\n",
    "        else:\n",
    "            image_path = os.path.join(self.image_dir, img_file_name)\n",
    "\n",
    "        # Load the image and convert to RGB\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Process the mask\n",
    "        mask = self.process_mask(img_id, image)\n",
    "        mask = Image.fromarray(mask.astype('uint8'))  # Convert to PIL image\n",
    "\n",
    "        # Transform the image and mask to [C, H, W]\n",
    "        image = self.transform(image)\n",
    "        mask = self.target_transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # image: PIL [H,W,C] -> [C,H,W]\n",
    "    # mask: numpy -> PIL [H,W,C] -> [C,H,W]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Create dataset for train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:22:55.872279Z",
     "start_time": "2024-11-02T19:22:54.284244Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-03T11:21:51.172696Z",
     "iopub.status.busy": "2024-11-03T11:21:51.172432Z",
     "iopub.status.idle": "2024-11-03T11:21:53.263730Z",
     "shell.execute_reply": "2024-11-03T11:21:53.262775Z",
     "shell.execute_reply.started": "2024-11-03T11:21:51.172672Z"
    }
   },
   "outputs": [],
   "source": [
    "# create train dateset\n",
    "train_dataset = CustomDataset(\n",
    "    image_dir=image_dir,\n",
    "    coco=coco,\n",
    "    transform=transform_method,\n",
    "    meta_data_dict=meta_data_dict,\n",
    "    target_transform=target_transform_method,\n",
    "    data_type='train'\n",
    ")\n",
    "\n",
    "# create valid dataset\n",
    "valid_dataset = CustomDataset(\n",
    "    image_dir=image_dir,\n",
    "    coco=coco,\n",
    "    transform=transform_method,\n",
    "    meta_data_dict=meta_data_dict,\n",
    "    target_transform=target_transform_method,\n",
    "    data_type='valid'\n",
    ")\n",
    "\n",
    "# create test dataset\n",
    "test_dataset = CustomDataset(\n",
    "    image_dir=image_dir,\n",
    "    coco=coco,\n",
    "    transform=transform_method,\n",
    "    meta_data_dict=meta_data_dict,\n",
    "    target_transform=target_transform_method,\n",
    "    data_type='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Create dataloader\n",
    "divide dataset into samll dataset in order to improving effiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:22:58.090471Z",
     "start_time": "2024-11-02T19:22:57.448518Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-03T11:21:53.264983Z",
     "iopub.status.busy": "2024-11-03T11:21:53.264721Z",
     "iopub.status.idle": "2024-11-03T11:21:54.357878Z",
     "shell.execute_reply": "2024-11-03T11:21:54.357102Z",
     "shell.execute_reply.started": "2024-11-03T11:21:53.264957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images: torch.Size([8, 3, 512, 512])\n",
      "Batch of masks: torch.Size([8, 512, 512])\n",
      "Masks dtype: torch.int64\n",
      "Masks value: tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# create valid DataLoader\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=4, shuffle=True)\n",
    "# create test DataLoader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "# create train DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# see the data set size\n",
    "for images, masks in train_dataloader:\n",
    "    print(\"Batch of images:\", images.shape)  # show the first image tensor\n",
    "    print(\"Batch of masks:\", masks.shape)    # show the first mask tensor\n",
    "    unique_values = torch.unique(masks)     \n",
    "    print(\"Masks dtype:\", masks.dtype)      # show the first mask dtype\n",
    "    print(\"Masks value:\", unique_values)    # show the first mask uniqe\n",
    "    break  # just want to the first one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Show dataloader size and dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T19:23:00.509639Z",
     "start_time": "2024-11-02T19:23:00.506945Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-03T11:21:54.359317Z",
     "iopub.status.busy": "2024-11-03T11:21:54.359012Z",
     "iopub.status.idle": "2024-11-03T11:21:54.364400Z",
     "shell.execute_reply": "2024-11-03T11:21:54.363733Z",
     "shell.execute_reply.started": "2024-11-03T11:21:54.359290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in the dataset: 5303\n",
      "Total number of images in the dataset: 1118\n",
      "Total number of images in the dataset: 2308\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of images in the dataset:\", len(train_dataset))\n",
    "print(\"Total number of images in the dataset:\", len(valid_dataset))\n",
    "print(\"Total number of images in the dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if PyTorch recognizes the GPU\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Half the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.5 * len(train_dataset))\n",
    "train_subset, _ = random_split(train_dataset, [train_size, len(train_dataset) - train_size])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_subset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Using UNet model to get iou and miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyw\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\andyw\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "# FCN model with a ResNet50 backbone\n",
    "model = models.segmentation.fcn_resnet50(pretrained=False)\n",
    "\n",
    "# Modify the classifier for the number of classes\n",
    "\n",
    "model.classifier[4] = torch.nn.Conv2d(512, num_classes, kernel_size=(1, 1))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# caculate iou function\n",
    "def calculate_iou(pred_mask, true_mask, num_classes):\n",
    "    ious = []\n",
    "    pred_mask = pred_mask.view(-1)  \n",
    "    true_mask = true_mask.view(-1)  \n",
    "\n",
    "    for cls in range(1, num_classes):  # only caculate iou for three classes\n",
    "        pred_inds = (pred_mask == cls)\n",
    "        true_inds = (true_mask == cls)\n",
    "        \n",
    "        intersection = (pred_inds & true_inds).sum().float()  \n",
    "        union = (pred_inds | true_inds).sum().float()  \n",
    "\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # avoid denominators of zero\n",
    "        else:\n",
    "            ious.append((intersection / union).item())  # append iou in list\n",
    "\n",
    "    return ious # return list\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Training Loss: 0.1081\n",
      "Model weights saved for epoch 1 at ./fcn_res/fcn_model_epoch1.pth\n",
      "Epoch [1/25], Validation mIoU: 0.7591\n",
      " - Class 1 'turtle' mIoU: 0.8540\n",
      " - Class 2 'flipper' mIoU: 0.7089\n",
      " - Class 3 'head' mIoU: 0.7144\n",
      "----------------------------------------------------------------\n",
      "Epoch [2/25], Training Loss: 0.0352\n",
      "Model weights saved for epoch 2 at ./fcn_res/fcn_model_epoch2.pth\n",
      "Epoch [2/25], Validation mIoU: 0.7911\n",
      " - Class 1 'turtle' mIoU: 0.8696\n",
      " - Class 2 'flipper' mIoU: 0.7502\n",
      " - Class 3 'head' mIoU: 0.7536\n",
      "----------------------------------------------------------------\n",
      "Epoch [3/25], Training Loss: 0.0261\n",
      "Model weights saved for epoch 3 at ./fcn_res/fcn_model_epoch3.pth\n",
      "Epoch [3/25], Validation mIoU: 0.8149\n",
      " - Class 1 'turtle' mIoU: 0.8859\n",
      " - Class 2 'flipper' mIoU: 0.7788\n",
      " - Class 3 'head' mIoU: 0.7800\n",
      "----------------------------------------------------------------\n",
      "Epoch [4/25], Training Loss: 0.0218\n",
      "Model weights saved for epoch 4 at ./fcn_res/fcn_model_epoch4.pth\n",
      "Epoch [4/25], Validation mIoU: 0.8047\n",
      " - Class 1 'turtle' mIoU: 0.8904\n",
      " - Class 2 'flipper' mIoU: 0.7689\n",
      " - Class 3 'head' mIoU: 0.7550\n",
      "----------------------------------------------------------------\n",
      "Epoch [5/25], Training Loss: 0.0213\n",
      "Model weights saved for epoch 5 at ./fcn_res/fcn_model_epoch5.pth\n",
      "Epoch [5/25], Validation mIoU: 0.8166\n",
      " - Class 1 'turtle' mIoU: 0.8887\n",
      " - Class 2 'flipper' mIoU: 0.7753\n",
      " - Class 3 'head' mIoU: 0.7858\n",
      "----------------------------------------------------------------\n",
      "Epoch [6/25], Training Loss: 0.0184\n",
      "Model weights saved for epoch 6 at ./fcn_res/fcn_model_epoch6.pth\n",
      "Epoch [6/25], Validation mIoU: 0.8209\n",
      " - Class 1 'turtle' mIoU: 0.8918\n",
      " - Class 2 'flipper' mIoU: 0.7865\n",
      " - Class 3 'head' mIoU: 0.7845\n",
      "----------------------------------------------------------------\n",
      "Epoch [7/25], Training Loss: 0.0146\n",
      "Model weights saved for epoch 7 at ./fcn_res/fcn_model_epoch7.pth\n",
      "Epoch [7/25], Validation mIoU: 0.8386\n",
      " - Class 1 'turtle' mIoU: 0.9031\n",
      " - Class 2 'flipper' mIoU: 0.8062\n",
      " - Class 3 'head' mIoU: 0.8065\n",
      "----------------------------------------------------------------\n",
      "Epoch [8/25], Training Loss: 0.0119\n",
      "Model weights saved for epoch 8 at ./fcn_res/fcn_model_epoch8.pth\n",
      "Epoch [8/25], Validation mIoU: 0.8436\n",
      " - Class 1 'turtle' mIoU: 0.9084\n",
      " - Class 2 'flipper' mIoU: 0.8132\n",
      " - Class 3 'head' mIoU: 0.8092\n",
      "----------------------------------------------------------------\n",
      "Epoch [9/25], Training Loss: 0.0192\n",
      "Model weights saved for epoch 9 at ./fcn_res/fcn_model_epoch9.pth\n",
      "Epoch [9/25], Validation mIoU: 0.7878\n",
      " - Class 1 'turtle' mIoU: 0.8806\n",
      " - Class 2 'flipper' mIoU: 0.7696\n",
      " - Class 3 'head' mIoU: 0.7131\n",
      "----------------------------------------------------------------\n",
      "Epoch [10/25], Training Loss: 0.0161\n",
      "Model weights saved for epoch 10 at ./fcn_res/fcn_model_epoch10.pth\n",
      "Epoch [10/25], Validation mIoU: 0.8057\n",
      " - Class 1 'turtle' mIoU: 0.8844\n",
      " - Class 2 'flipper' mIoU: 0.7834\n",
      " - Class 3 'head' mIoU: 0.7494\n",
      "----------------------------------------------------------------\n",
      "Epoch [11/25], Training Loss: 0.0142\n",
      "Model weights saved for epoch 11 at ./fcn_res/fcn_model_epoch11.pth\n",
      "Epoch [11/25], Validation mIoU: 0.8416\n",
      " - Class 1 'turtle' mIoU: 0.9035\n",
      " - Class 2 'flipper' mIoU: 0.8077\n",
      " - Class 3 'head' mIoU: 0.8137\n",
      "----------------------------------------------------------------\n",
      "Epoch [12/25], Training Loss: 0.0109\n",
      "Model weights saved for epoch 12 at ./fcn_res/fcn_model_epoch12.pth\n",
      "Epoch [12/25], Validation mIoU: 0.8453\n",
      " - Class 1 'turtle' mIoU: 0.9085\n",
      " - Class 2 'flipper' mIoU: 0.8172\n",
      " - Class 3 'head' mIoU: 0.8103\n",
      "----------------------------------------------------------------\n",
      "Epoch [13/25], Training Loss: 0.0091\n",
      "Model weights saved for epoch 13 at ./fcn_res/fcn_model_epoch13.pth\n",
      "Epoch [13/25], Validation mIoU: 0.8581\n",
      " - Class 1 'turtle' mIoU: 0.9150\n",
      " - Class 2 'flipper' mIoU: 0.8278\n",
      " - Class 3 'head' mIoU: 0.8314\n",
      "----------------------------------------------------------------\n",
      "Epoch [14/25], Training Loss: 0.0084\n",
      "Model weights saved for epoch 14 at ./fcn_res/fcn_model_epoch14.pth\n",
      "Epoch [14/25], Validation mIoU: 0.8554\n",
      " - Class 1 'turtle' mIoU: 0.9133\n",
      " - Class 2 'flipper' mIoU: 0.8282\n",
      " - Class 3 'head' mIoU: 0.8247\n",
      "----------------------------------------------------------------\n",
      "Epoch [15/25], Training Loss: 0.0079\n",
      "Model weights saved for epoch 15 at ./fcn_res/fcn_model_epoch15.pth\n",
      "Epoch [15/25], Validation mIoU: 0.8593\n",
      " - Class 1 'turtle' mIoU: 0.9173\n",
      " - Class 2 'flipper' mIoU: 0.8323\n",
      " - Class 3 'head' mIoU: 0.8282\n",
      "----------------------------------------------------------------\n",
      "Epoch [16/25], Training Loss: 0.0075\n",
      "Model weights saved for epoch 16 at ./fcn_res/fcn_model_epoch16.pth\n",
      "Epoch [16/25], Validation mIoU: 0.8629\n",
      " - Class 1 'turtle' mIoU: 0.9163\n",
      " - Class 2 'flipper' mIoU: 0.8350\n",
      " - Class 3 'head' mIoU: 0.8374\n",
      "----------------------------------------------------------------\n",
      "Epoch [17/25], Training Loss: 0.0072\n",
      "Model weights saved for epoch 17 at ./fcn_res/fcn_model_epoch17.pth\n",
      "Epoch [17/25], Validation mIoU: 0.8562\n",
      " - Class 1 'turtle' mIoU: 0.9154\n",
      " - Class 2 'flipper' mIoU: 0.8297\n",
      " - Class 3 'head' mIoU: 0.8236\n",
      "----------------------------------------------------------------\n",
      "Epoch [18/25], Training Loss: 0.0071\n",
      "Model weights saved for epoch 18 at ./fcn_res/fcn_model_epoch18.pth\n",
      "Epoch [18/25], Validation mIoU: 0.8581\n",
      " - Class 1 'turtle' mIoU: 0.9149\n",
      " - Class 2 'flipper' mIoU: 0.8312\n",
      " - Class 3 'head' mIoU: 0.8283\n",
      "----------------------------------------------------------------\n",
      "Epoch [19/25], Training Loss: 0.0069\n",
      "Model weights saved for epoch 19 at ./fcn_res/fcn_model_epoch19.pth\n",
      "Epoch [19/25], Validation mIoU: 0.8630\n",
      " - Class 1 'turtle' mIoU: 0.9178\n",
      " - Class 2 'flipper' mIoU: 0.8323\n",
      " - Class 3 'head' mIoU: 0.8389\n",
      "----------------------------------------------------------------\n",
      "Epoch [20/25], Training Loss: 0.0277\n",
      "Model weights saved for epoch 20 at ./fcn_res/fcn_model_epoch20.pth\n",
      "Epoch [20/25], Validation mIoU: 0.7730\n",
      " - Class 1 'turtle' mIoU: 0.8427\n",
      " - Class 2 'flipper' mIoU: 0.7601\n",
      " - Class 3 'head' mIoU: 0.7163\n",
      "----------------------------------------------------------------\n",
      "Epoch [21/25], Training Loss: 0.0165\n",
      "Model weights saved for epoch 21 at ./fcn_res/fcn_model_epoch21.pth\n",
      "Epoch [21/25], Validation mIoU: 0.8389\n",
      " - Class 1 'turtle' mIoU: 0.8957\n",
      " - Class 2 'flipper' mIoU: 0.8104\n",
      " - Class 3 'head' mIoU: 0.8106\n",
      "----------------------------------------------------------------\n",
      "Epoch [22/25], Training Loss: 0.0092\n",
      "Model weights saved for epoch 22 at ./fcn_res/fcn_model_epoch22.pth\n",
      "Epoch [22/25], Validation mIoU: 0.8584\n",
      " - Class 1 'turtle' mIoU: 0.9095\n",
      " - Class 2 'flipper' mIoU: 0.8304\n",
      " - Class 3 'head' mIoU: 0.8352\n",
      "----------------------------------------------------------------\n",
      "Epoch [23/25], Training Loss: 0.0076\n",
      "Model weights saved for epoch 23 at ./fcn_res/fcn_model_epoch23.pth\n",
      "Epoch [23/25], Validation mIoU: 0.8587\n",
      " - Class 1 'turtle' mIoU: 0.9140\n",
      " - Class 2 'flipper' mIoU: 0.8345\n",
      " - Class 3 'head' mIoU: 0.8274\n",
      "----------------------------------------------------------------\n",
      "Epoch [24/25], Training Loss: 0.0070\n",
      "Model weights saved for epoch 24 at ./fcn_res/fcn_model_epoch24.pth\n",
      "Epoch [24/25], Validation mIoU: 0.8604\n",
      " - Class 1 'turtle' mIoU: 0.9137\n",
      " - Class 2 'flipper' mIoU: 0.8330\n",
      " - Class 3 'head' mIoU: 0.8346\n",
      "----------------------------------------------------------------\n",
      "Epoch [25/25], Training Loss: 0.0066\n",
      "Model weights saved for epoch 25 at ./fcn_res/fcn_model_epoch25.pth\n",
      "Epoch [25/25], Validation mIoU: 0.8614\n",
      " - Class 1 'turtle' mIoU: 0.9158\n",
      " - Class 2 'flipper' mIoU: 0.8381\n",
      " - Class 3 'head' mIoU: 0.8303\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not collections.OrderedDict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     80\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m---> 81\u001b[0m pred_masks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m     84\u001b[0m     ious \u001b[38;5;241m=\u001b[39m calculate_iou(pred_masks[i], masks[i], num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not collections.OrderedDict"
     ]
    }
   ],
   "source": [
    "# Directory to save the model weights\n",
    "os.makedirs('./fcn_res', exist_ok=True)\n",
    "save_path = './fcn_res/fcn_model_epoch{}.pth'\n",
    "\n",
    "# ----------------------\n",
    "# Training Phase\n",
    "# ----------------------\n",
    "num_epochs = 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, masks in train_dataloader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        masks = masks.squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)[\"out\"]\n",
    "        loss = criterion(outputs, masks.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print training loss\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Save model weights at the end of each epoch\n",
    "    torch.save(model.state_dict(), save_path.format(epoch + 1))\n",
    "    print(f\"Model weights saved for epoch {epoch + 1} at {save_path.format(epoch + 1)}\")\n",
    "\n",
    "    # ----------------------\n",
    "    # Validation Phase\n",
    "    # ----------------------\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_ious = []  # Record all IoUs in one epoch\n",
    "\n",
    "    with torch.no_grad():  # No gradient computation\n",
    "        for images, masks in valid_dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            masks = masks.squeeze(1)\n",
    "\n",
    "            outputs = model(images)[\"out\"]\n",
    "            pred_masks = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                ious = calculate_iou(pred_masks[i], masks[i], num_classes=num_classes)\n",
    "                all_ious.append(ious)\n",
    "\n",
    "    # Calculate mIoU and average of total mIoU\n",
    "    all_ious_tensor = torch.tensor(all_ious)\n",
    "    mean_ious = torch.nanmean(all_ious_tensor, dim=0)\n",
    "    avg_all_mious = torch.nanmean(mean_ious).item()\n",
    "\n",
    "    # Print validation results\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation mIoU: {avg_all_mious:.4f}\")\n",
    "    for cls in range(num_classes):\n",
    "        if cls == 0:\n",
    "            print(f\" - Class {cls + 1} 'turtle' mIoU: {mean_ious[cls].item():.4f}\")\n",
    "        elif cls == 1:\n",
    "            print(f\" - Class {cls + 1} 'flipper' mIoU: {mean_ious[cls].item():.4f}\")\n",
    "        elif cls == 2:\n",
    "            print(f\" - Class {cls + 1} 'head' mIoU: {mean_ious[cls].item():.4f}\")\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore the TypeError Above, Testing is Moved below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the average of three class mIoU: 0.8543\n",
      " - Class 1 'turtle' mIoU: 0.9233\n",
      " - Class 2 'flipper' mIoU: 0.8379\n",
      " - Class 3 'head' mIoU: 0.8017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------\n",
    "# Testing Phase\n",
    "# ----------------------\n",
    "model.eval()\n",
    "test_ious = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_dataloader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        masks = masks.squeeze(1)\n",
    "\n",
    "        outputs = model(images)[\"out\"]\n",
    "        pred_masks = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        for i in range(images.size(0)):\n",
    "            ious = calculate_iou(pred_masks[i], masks[i], num_classes=num_classes)\n",
    "            test_ious.append(ious)\n",
    "\n",
    "# Calculate mIoU and average of total mIoU for testing\n",
    "all_ious_tensor = torch.tensor(test_ious)\n",
    "mean_ious = torch.nanmean(all_ious_tensor, dim=0)\n",
    "avg_all_mious = torch.nanmean(mean_ious).item()\n",
    "\n",
    "# Print test results\n",
    "print(f\"Testing the average of three class mIoU: {avg_all_mious:.4f}\")\n",
    "for cls in range(num_classes):\n",
    "    if cls == 0:\n",
    "        print(f\" - Class {cls + 1} 'turtle' mIoU: {mean_ious[cls].item():.4f}\")\n",
    "    elif cls == 1:\n",
    "        print(f\" - Class {cls + 1} 'flipper' mIoU: {mean_ious[cls].item():.4f}\")\n",
    "    elif cls == 2:\n",
    "        print(f\" - Class {cls + 1} 'head' mIoU: {mean_ious[cls].item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Using weighted voting\n",
    "This section includes our ensemble model for testing set usign 30% weight for FCN, U-Net, Deeplabv3 for their high performance and 10% for Deeplabv3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_weights_path = './models/fcn_model.pth'           # state_dict\n",
    "unet_weights_path = './models/unet_model.pth'         # state_dict\n",
    "deeplabv3_weights_path = './models/deeplabv3_model.pth'  # full model\n",
    "deeplabv3p_weights_path = './models/deeplabv3_plus_model.pth' # full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyw\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\andyw\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\andyw\\AppData\\Local\\Temp\\ipykernel_13904\\1793462439.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fcn_model.load_state_dict(torch.load(fcn_weights_path))\n",
      "C:\\Users\\andyw\\AppData\\Local\\Temp\\ipykernel_13904\\1793462439.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unet_model.load_state_dict(torch.load(unet_weights_path))\n",
      "C:\\Users\\andyw\\AppData\\Local\\Temp\\ipykernel_13904\\1793462439.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  deeplabv3_model = torch.load(deeplabv3_weights_path)  # Directly load full model\n",
      "C:\\Users\\andyw\\AppData\\Local\\Temp\\ipykernel_13904\\1793462439.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  deeplabv3p_model = torch.load(deeplabv3p_weights_path)  # Directly load full model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepLabV3Plus(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): DeepLabV3PlusDecoder(\n",
       "    (aspp): Sequential(\n",
       "      (0): ASPP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False)\n",
       "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False)\n",
       "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (3): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=2048, bias=False)\n",
       "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (4): ASPPPooling(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SeparableConv2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): SeparableConv2d(\n",
       "        (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
       "        (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from torchvision import models\n",
    "from segmentation_models_pytorch import Unet, DeepLabV3Plus\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 4  # Background, turtle, flipper, head\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --------------------------\n",
    "# Load FCN Model (state_dict)\n",
    "# --------------------------\n",
    "fcn_model = models.segmentation.fcn_resnet50(pretrained=False)\n",
    "fcn_model.classifier[4] = torch.nn.Conv2d(512, num_classes, kernel_size=(1, 1))\n",
    "fcn_model.load_state_dict(torch.load(fcn_weights_path))\n",
    "fcn_model = fcn_model.to(device)\n",
    "fcn_model.eval()\n",
    "\n",
    "# --------------------------\n",
    "# Load UNet Model (state_dict)\n",
    "# --------------------------\n",
    "unet_model = Unet('resnet34', classes=num_classes, activation=None)\n",
    "unet_model.load_state_dict(torch.load(unet_weights_path))\n",
    "unet_model = unet_model.to(device)\n",
    "unet_model.eval()\n",
    "\n",
    "# --------------------------\n",
    "# Load DeepLabV3 Model (full model)\n",
    "# --------------------------\n",
    "deeplabv3_model = torch.load(deeplabv3_weights_path)  # Directly load full model\n",
    "deeplabv3_model = deeplabv3_model.to(device)\n",
    "deeplabv3_model.eval()\n",
    "\n",
    "# --------------------------\n",
    "# Load DeepLabV3+ Model (full model)\n",
    "# --------------------------\n",
    "deeplabv3p_model = torch.load(deeplabv3p_weights_path)  # Directly load full model\n",
    "deeplabv3p_model = deeplabv3p_model.to(device)\n",
    "deeplabv3p_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the stored base models, obtain the predictions of the testing set for each model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "test_preds_fcn, test_preds_unet, test_preds_deeplabv3, test_preds_deeplabv3p = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_dataloader:  # No need for ground truth masks here\n",
    "        images = images.to(device)\n",
    "\n",
    "        # FCN predictions\n",
    "        outputs_fcn = fcn_model(images)['out']\n",
    "        test_preds_fcn.append(torch.argmax(outputs_fcn, dim=1).cpu())\n",
    "\n",
    "        # UNet predictions\n",
    "        outputs_unet = unet_model(images)\n",
    "        test_preds_unet.append(torch.argmax(outputs_unet, dim=1).cpu())\n",
    "\n",
    "        # DeepLabV3 predictions\n",
    "        outputs_deeplabv3 = deeplabv3_model(images)['out']\n",
    "        test_preds_deeplabv3.append(torch.argmax(outputs_deeplabv3, dim=1).cpu())\n",
    "\n",
    "        # DeepLabV3+ predictions\n",
    "        outputs_deeplabv3p = deeplabv3p_model(images)\n",
    "        test_preds_deeplabv3p.append(torch.argmax(outputs_deeplabv3p, dim=1).cpu())\n",
    "\n",
    "# Concatenate all predictions\n",
    "test_preds_fcn = torch.cat(test_preds_fcn, dim=0)\n",
    "test_preds_unet = torch.cat(test_preds_unet, dim=0)\n",
    "test_preds_deeplabv3 = torch.cat(test_preds_deeplabv3, dim=0)\n",
    "test_preds_deeplabv3p = torch.cat(test_preds_deeplabv3p, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "os.makedirs('./predictions', exist_ok=True)\n",
    "\n",
    "# Save predictions to disk just in case kernel crashes\n",
    "torch.save(test_preds_fcn, './predictions/test_preds_fcn.pt')\n",
    "torch.save(test_preds_unet, './predictions/test_preds_unet.pt')\n",
    "torch.save(test_preds_deeplabv3, './predictions/test_preds_deeplabv3.pt')\n",
    "torch.save(test_preds_deeplabv3p, './predictions/test_preds_deeplabv3p.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ensemble predictions useing weighted voting and the 4 models prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for the models\n",
    "weight_fcn = 0.3\n",
    "weight_unet = 0.3\n",
    "weight_deeplabv3 = 0.3\n",
    "weight_deeplabv3p = 0.1\n",
    "\n",
    "# Initialize variables for storing results\n",
    "num_classes = 4\n",
    "# Store final predictions\n",
    "ensemble_preds = []\n",
    "\n",
    "# Process predictions batch-wise\n",
    "# Adjust batch size based on available memory\n",
    "batch_size = 16\n",
    "\n",
    "for start_idx in range(0, test_preds_fcn.size(0), batch_size):\n",
    "    end_idx = min(start_idx + batch_size, test_preds_fcn.size(0))\n",
    "\n",
    "    # Slice predictions for the current batch\n",
    "    batch_fcn = test_preds_fcn[start_idx:end_idx]\n",
    "    batch_unet = test_preds_unet[start_idx:end_idx]\n",
    "    batch_deeplabv3 = test_preds_deeplabv3[start_idx:end_idx]\n",
    "    batch_deeplabv3p = test_preds_deeplabv3p[start_idx:end_idx]\n",
    "\n",
    "    # Convert batch predictions to one-hot encoded probabilities\n",
    "    fcn_one_hot = torch.nn.functional.one_hot(batch_fcn, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "    unet_one_hot = torch.nn.functional.one_hot(batch_unet, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "    deeplabv3_one_hot = torch.nn.functional.one_hot(batch_deeplabv3, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "    deeplabv3p_one_hot = torch.nn.functional.one_hot(batch_deeplabv3p, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    # Aggregate weighted probabilities for the current batch\n",
    "    weighted_probs = (\n",
    "        weight_fcn * fcn_one_hot\n",
    "        + weight_unet * unet_one_hot\n",
    "        + weight_deeplabv3 * deeplabv3_one_hot\n",
    "        + weight_deeplabv3p * deeplabv3p_one_hot\n",
    "    )\n",
    "\n",
    "    # Get final predictions for the current batch\n",
    "    batch_preds = torch.argmax(weighted_probs, dim=1)\n",
    "    ensemble_preds.append(batch_preds)\n",
    "\n",
    "# Concatenate predictions for all batches\n",
    "ensemble_preds = torch.cat(ensemble_preds, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ground truth masks from the test dataloader\n",
    "test_masks = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, masks in test_dataloader:\n",
    "        test_masks.append(masks)\n",
    "\n",
    "# Concatenate all masks into a single tensor\n",
    "test_masks = torch.cat(test_masks, dim=0)  # Shape: [N, H, W]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ensemble model IoU and MIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Testing Results:\n",
      " - Overall mIoU (excluding background): 0.8709\n",
      " - Class 1 (Turtle): mIoU: 0.9328\n",
      " - Class 2 (Flipper): mIoU: 0.8580\n",
      " - Class 3 (Head): mIoU: 0.8218\n"
     ]
    }
   ],
   "source": [
    "# IoU and mIoU calculation\n",
    "test_ious = []\n",
    "\n",
    "# Evaluate IoU for each prediction\n",
    "for i in range(ensemble_preds.size(0)):\n",
    "    ious = calculate_iou(ensemble_preds[i], test_masks[i], num_classes=num_classes)\n",
    "    test_ious.append(ious)\n",
    "\n",
    "# Convert IoU list to a tensor for further analysis\n",
    "all_ious_tensor = torch.tensor(test_ious)  # Shape: [N, num_classes]\n",
    "\n",
    "# Calculate mean IoU per class\n",
    "mean_ious = torch.nanmean(all_ious_tensor, dim=0)  # [num_classes]\n",
    "\n",
    "# Calculate overall mean IoU (mIoU)\n",
    "avg_all_mious = torch.nanmean(mean_ious).item()\n",
    "\n",
    "# Print results\n",
    "# Print IoU for each class (ignore background)\n",
    "print(f\"Ensemble Testing Results:\")\n",
    "print(f\" - Overall mIoU (excluding background): {avg_all_mious:.4f}\")\n",
    "print(f\" - Class 1 (Turtle): mIoU: {mean_ious[0].item():.4f}\")\n",
    "print(f\" - Class 2 (Flipper): mIoU: {mean_ious[1].item():.4f}\")\n",
    "print(f\" - Class 3 (Head): mIoU: {mean_ious[2].item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a sample plot to visualise in report and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize predictions and ground truth for a random sample\n",
    "idx = 0  # Change to visualize different samples\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Prediction\")\n",
    "plt.imshow(ensemble_preds[idx].cpu(), cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Ground truth mask\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.imshow(test_masks[idx].cpu(), cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Difference (for debugging)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Difference\")\n",
    "plt.imshow((ensemble_preds[idx] != test_masks[idx]).cpu(), cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
